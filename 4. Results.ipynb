{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed04ecc",
   "metadata": {},
   "source": [
    "# Results\n",
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import lightning.pytorch as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from pytorch_forecasting import Baseline, TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer, GroupNormalizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b744e8",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Directory = 'C:/.../TFT_for_Stock_Movement_Prediction/data'\n",
    "Directory = 'C:/.../TFT_for_Stock_Movement_Prediction/results'\n",
    "\n",
    "# Target\n",
    "T = pd.read_csv(os.path.join(Directory, 'CCR.csv'), index_col = [0])[750:3250].reset_index(drop = True)\n",
    "\n",
    "# Trading feature\n",
    "constituents_data = pd.read_csv(os.path.join(Directory, 'constituents_data.csv'), index_col = [0], header = [0, 1])[750:3251].reset_index(drop = True)\n",
    "\n",
    "## Model results\n",
    "# Individual\n",
    "RI = pd.read_csv(os.path.join(Directory2, 'Individual/Nr.1/Results_Individual.csv'), index_col = [0])\n",
    "RIp90 = pd.read_csv(os.path.join(Directory2, 'Individual/Nr.1/Results_p90_Individual.csv'), index_col = [0])\n",
    "\n",
    "RI2 = pd.read_csv(os.path.join(Directory2, 'Individual/Nr.2/Results_Individual.csv'), index_col = [0])\n",
    "RI2p90 = pd.read_csv(os.path.join(Directory2, 'Individual/Nr.2/Results_p90_Individual.csv'), index_col = [0])\n",
    "\n",
    "# Portfolio\n",
    "RP = pd.read_csv(os.path.join(Directory2, 'Global/Nr.1/Results_Global.csv'), index_col = [0])\n",
    "RPp90 = pd.read_csv(os.path.join(Directory2, 'Global/Nr.1/Results_p90_Global.csv'), index_col = [0])\n",
    "\n",
    "RP2 = pd.read_csv(os.path.join(Directory2, 'Global/Nr.2/Results_Global.csv'), index_col = [0])\n",
    "RP2p90 = pd.read_csv(os.path.join(Directory2, 'Global/Nr.2/Results_p90_Global.csv'), index_col = [0])\n",
    "\n",
    "# Sector portfolio\n",
    "RPS = pd.read_csv(os.path.join(Directory2, 'Global_sector/Nr.1/Results_Global_sector.csv'), index_col = [0])\n",
    "RPSp90 = pd.read_csv(os.path.join(Directory2, 'Global_sector/Nr.1/Results_p90_Global_sector.csv'), index_col = [0])\n",
    "\n",
    "RPS2 = pd.read_csv(os.path.join(Directory2, 'Global_sector/Nr.2/Results_Global_sector.csv'), index_col = [0])\n",
    "RPS2p90 = pd.read_csv(os.path.join(Directory2, 'Global_sector/Nr.2/Results_p90_Global_sector.csv'), index_col = [0])\n",
    "\n",
    "# FNN\n",
    "RMLP1 = pd.read_csv(os.path.join(Directory2, 'FNN/Nr.1/Results_FNN.csv'), index_col = [0])\n",
    "RMLP2 = pd.read_csv(os.path.join(Directory2, 'FNN/Nr.2/Results_FNN.csv'), index_col = [0])\n",
    "\n",
    "# ARIMA\n",
    "RA = pd.read_csv(os.path.join(Directory2, 'ARIMA/Results_ARIMA.csv'), index_col = [0])\n",
    "\n",
    "# Baseline\n",
    "B = pd.read_csv(os.path.join(Directory2, 'Baseline/Baseline.csv'), index_col = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f34dc",
   "metadata": {},
   "source": [
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2db36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "M = RI2\n",
    "Quantile = 0.5\n",
    "\n",
    "# Define study periods length\n",
    "period_b = 0, 250, 500, 750, 1000, 1250, 1500, 1750, 2000, 2250\n",
    "period_e = 1000, 1250, 1500, 1750, 2000, 2250, 2500, 2750, 3000, 3250\n",
    "test_size = 250\n",
    "\n",
    "# Transaction costs\n",
    "tc = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03fc13",
   "metadata": {},
   "source": [
    "### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21bb046",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Forecast evaluation\n",
    "Mmae = pd.DataFrame(index = range(len(period_b)), columns = M.columns)\n",
    "Mrmse = pd.DataFrame(index = range(len(period_b)), columns = M.columns)\n",
    "Mq = pd.DataFrame(index = range(len(period_b)), columns = M.columns)\n",
    "b = period_b[0]\n",
    "e = test_size\n",
    "temp = 0\n",
    "for i in range(len(period_b)):\n",
    "    for j in M.columns:\n",
    "        for k in range(b, e):\n",
    "            temp += max(Quantile * (T[j][k] - M[j][k]), (1 - Quantile) * (M[j][k] - T[j][k]))\n",
    "        Mq[j][i] = temp / test_size\n",
    "        temp = 0\n",
    "        Mmae[j][i] = mean_absolute_error(T[j][b:e], M[j][b:e])\n",
    "        Mrmse[j][i] = mean_squared_error(T[j][b:e], M[j][b:e], squared = False)\n",
    "    b += test_size\n",
    "    e += test_size\n",
    "print(f'Q{Quantile}: {round(sum(Mq.apply(np.sum)) / len(period_b) / len(M.columns), 4)}')\n",
    "print(f'MAE: {round(mean_absolute_error(T, M), 4)}')\n",
    "print(f'RMSE: {round(mean_squared_error(T, M, squared = False), 4)}')\n",
    "\n",
    "### Trading evaluation\n",
    "## Daily trading\n",
    "Md = pd.DataFrame(data = np.where(M, M >= 0, 1), index = M.index, columns = M.columns)#-----------# Model\n",
    "#Md = pd.DataFrame((1), index = M.index, columns = M.columns)#------------------------------------# Buy and hold\n",
    "#Md = pd.DataFrame(data = np.where(T, T >= 0, 1), index = M.index, columns = M.columns)#----------# Optimal\n",
    "long_r = 0\n",
    "short_r = 0\n",
    "for r in range(len(M)):\n",
    "    temp_l = sum(T.loc[r][T.columns.intersection(Md.loc[r][Md.loc[r] == 1].index)]) / len(M.columns) / len(M)\n",
    "    temp_s = sum(T.loc[r][T.columns.intersection(Md.loc[r][Md.loc[r] == 0].index)]) / len(M.columns) / len(M)\n",
    "    long_r += temp_l * 100\n",
    "    short_r += temp_s * 100\n",
    "print('-----------------------Daily trading-----------------------')\n",
    "print(f'Mean daily return: {round((long_r - short_r), 4)}%')\n",
    "print(f'Mean daily return with transaction costs: {round(long_r - short_r - tc, 4)}%')\n",
    "\n",
    "## Daily change trading evaluation\n",
    "# Daily\n",
    "Mdr = pd.DataFrame(index = range(len(M)), columns = M.columns)\n",
    "Mdt = pd.DataFrame(index = range(len(M)), columns = M.columns)\n",
    "Mdrt = pd.DataFrame(index = range(len(M)), columns = M.columns)\n",
    "# Study period\n",
    "Mdrp = pd.DataFrame(index = range(len(period_b)), columns = M.columns)\n",
    "Mdrtp = pd.DataFrame(index = range(len(period_b)), columns = M.columns)\n",
    "Mt = pd.DataFrame(index = range(len(period_b)), columns = M.columns)\n",
    "Long = 0\n",
    "Short = 0\n",
    "for g in M.columns:\n",
    "    j = 1\n",
    "    k = 0\n",
    "    t = 0\n",
    "    for h in range(len(period_b)):\n",
    "        long_r = 0\n",
    "        short_r = 0\n",
    "        for i in range(test_size):\n",
    "            if j == period_b[h] + test_size and Md[g][j - 2] == Md[g][j - 1]:\n",
    "                if Md[g][k] == 1:\n",
    "                    Mdr[g][j - 1] = ((constituents_data['Close'][g][j] / constituents_data['Close'][g][k]) - 1)\n",
    "                    long_r += ((constituents_data['Close'][g][j] / constituents_data['Close'][g][k]) - 1)\n",
    "                else:\n",
    "                    Mdr[g][j - 1] = -((constituents_data['Close'][g][j] / constituents_data['Close'][g][k]) - 1)\n",
    "                    short_r += -((constituents_data['Close'][g][j] / constituents_data['Close'][g][k]) - 1)\n",
    "            elif j == period_b[h] + test_size and Md[g][j - 2] != Md[g][j - 1]:\n",
    "                if Md[g][j - 1] == 1:\n",
    "                    Mdr[g][j - 1] = ((constituents_data['Close'][g][j] / constituents_data['Close'][g][j - 1]) - 1)\n",
    "                    long_r += ((constituents_data['Close'][g][j] / constituents_data['Close'][g][j - 1]) - 1)\n",
    "                else:\n",
    "                    Mdr[g][j - 1] = -((constituents_data['Close'][g][j] / constituents_data['Close'][g][j - 1]) - 1)\n",
    "                    short_r += -((constituents_data['Close'][g][j] / constituents_data['Close'][g][j - 1]) - 1)\n",
    "            elif Md[g][k] != Md[g][j]:\n",
    "                if Md[g][k] == 1:\n",
    "                    Mdr[g][j - 1] = ((constituents_data['Close'][g][j] / constituents_data['Close'][g][k]) - 1)\n",
    "                    long_r += ((constituents_data['Close'][g][j] / constituents_data['Close'][g][k]) - 1)\n",
    "                else:\n",
    "                    Mdr[g][j - 1] = -((constituents_data['Close'][g][j] / constituents_data['Close'][g][k]) - 1)\n",
    "                    short_r += -((constituents_data['Close'][g][j] / constituents_data['Close'][g][k]) - 1)\n",
    "                j += 1\n",
    "                k = j - 1\n",
    "                t += 1\n",
    "            else:\n",
    "                j += 1\n",
    "            if i == 0:\n",
    "                Mdt[g][j - 2] = -tc / 2\n",
    "            elif i == test_size - 1:\n",
    "                Mdt[g][j - 1] = -tc / 2\n",
    "            if i == 0 and pd.isna(Mdr[g][j - 2]) == False:\n",
    "                Mdt[g][j - 2] += -tc\n",
    "            if i != 0 and i != test_size - 1 and pd.isna(Mdr[g][j - 2]) == False:\n",
    "                Mdt[g][j - 2] = -tc\n",
    "        Long += long_r / test_size * 100\n",
    "        Short += short_r / test_size * 100\n",
    "        Mt[g][h] = t + 1\n",
    "        Mdrp[g][h] = (long_r + short_r) * 100 / test_size\n",
    "        Mdrtp[g][h] = ((long_r + short_r) * 100  / test_size) - (tc * (t + 1) / test_size)\n",
    "        j = 1\n",
    "        k = 0\n",
    "        t = 0\n",
    "        j += (h + 1) * test_size\n",
    "        k += (h + 1) * test_size\n",
    "print('-----------------------Change trading----------------------')\n",
    "print(f'Mean daily long postiton return: {round(Long / len(period_b) / len(M.columns), 4)}%')\n",
    "print(f'Mean daily short postiton return: {round(Short / len(period_b) / len(M.columns), 4)}%')\n",
    "print(f'Mean daily return: {round((sum(Mdr.apply(np.sum)) / len(M) / len(M.columns)) * 100, 4)}%')\n",
    "print(f'Mean standard deviation: {round(sum(Mdr.apply(np.std)) / len(M.columns) * 100, 4)}%')\n",
    "print(f'Mean daily transaction costs: {round(sum(Mt.apply(np.sum)) / len(M) / len(M.columns) * tc, 4)}% with {sum(Mt.apply(np.sum))} trades ({round(sum(Mt.apply(np.sum)) / len(M), 4)} trades per day)')\n",
    "print(f'Mean daily return with transaction costs: {round((sum(Mdr.apply(np.sum)) / len(M) / len(M.columns)) * 100 + sum(Mdt.apply(np.sum)) / len(M) / len(M.columns), 4)}%')\n",
    "Mdr = Mdr.fillna(0) * 100\n",
    "Mdrt = Mdr + Mdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1bf80",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decdca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual\n",
    "mq_Individual = (Mmae.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rp_Individual = (Mdrp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rtp_Individual = (Mdrtp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "\n",
    "temp = ((Mdr).apply(np.sum, axis = 1) / len(M.columns))\n",
    "r_Individual = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "r_Individual['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    r_Individual['Profit'][i] = r_Individual['Profit'][i - 1] + temp[i]\n",
    "    \n",
    "temp = ((Mdrt).apply(np.sum, axis = 1) / len(M.columns))\n",
    "rt_Individual = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "rt_Individual['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    rt_Individual['Profit'][i] = rt_Individual['Profit'][i - 1] + temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36902cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global\n",
    "mq_Portfolio = (Mmae.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rp_Portfolio = (Mdrp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rtp_Portfolio = (Mdrtp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "\n",
    "temp = ((Mdr).apply(np.sum, axis = 1) / len(M.columns))\n",
    "r_Portfolio = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "r_Portfolio['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    r_Portfolio['Profit'][i] = r_Portfolio['Profit'][i - 1] + temp[i]\n",
    "    \n",
    "temp = ((Mdrt).apply(np.sum, axis = 1) / len(M.columns))\n",
    "rt_Portfolio = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "rt_Portfolio['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    rt_Portfolio['Profit'][i] = rt_Portfolio['Profit'][i - 1] + temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global sector\n",
    "mq_Portfolio2 = (Mmae.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rp_Portfolio2 = (Mdrp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rtp_Portfolio2 = (Mdrtp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "\n",
    "temp = ((Mdr).apply(np.sum, axis = 1) / len(M.columns))\n",
    "r_Portfolio2 = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "r_Portfolio2['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    r_Portfolio2['Profit'][i] = r_Portfolio2['Profit'][i - 1] + temp[i]\n",
    "    \n",
    "temp = ((Mdrt).apply(np.sum, axis = 1) / len(M.columns))\n",
    "rt_Portfolio2 = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "rt_Portfolio2['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    rt_Portfolio2['Profit'][i] = rt_Portfolio2['Profit'][i - 1] + temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNN\n",
    "mq_MLP = (Mmae.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rp_MLP = (Mdrp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rtp_MLP = (Mdrtp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "\n",
    "temp = ((Mdr).apply(np.sum, axis = 1) / len(M.columns))\n",
    "r_MLP = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "r_MLP['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    r_MLP['Profit'][i] = r_MLP['Profit'][i - 1] + temp[i]\n",
    "    \n",
    "temp = ((Mdrt).apply(np.sum, axis = 1) / len(M.columns))\n",
    "rt_MLP = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "rt_MLP['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    rt_MLP['Profit'][i] = rt_MLP['Profit'][i - 1] + temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA\n",
    "mq_ARIMA = (Mmae.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rp_ARIMA = (Mdrp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rtp_ARIMA = (Mdrtp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "\n",
    "temp = ((Mdr).apply(np.sum, axis = 1) / len(M.columns))\n",
    "r_ARIMA = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "r_ARIMA['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    r_ARIMA['Profit'][i] = r_ARIMA['Profit'][i - 1] + temp[i]\n",
    "    \n",
    "temp = ((Mdrt).apply(np.sum, axis = 1) / len(M.columns))\n",
    "rt_ARIMA = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "rt_ARIMA['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    rt_ARIMA['Profit'][i] = rt_ARIMA['Profit'][i - 1] + temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f14247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buy and hold\n",
    "rp_Bh = (Mdrp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rtp_Bh = (Mdrtp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "\n",
    "temp = ((Mdr).apply(np.sum, axis = 1) / len(M.columns))\n",
    "r_Bh = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "r_Bh['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    r_Bh['Profit'][i] = r_Bh['Profit'][i - 1] + temp[i]\n",
    "    \n",
    "temp = ((Mdrt).apply(np.sum, axis = 1) / len(M.columns))\n",
    "rt_Bh = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "rt_Bh['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    rt_Bh['Profit'][i] = rt_Bh['Profit'][i - 1] + temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal\n",
    "rp_Opt = (Mdrp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "rtp_Opt = (Mdrtp.apply(np.sum, axis = 1) / len(M.columns)).values\n",
    "\n",
    "temp = ((Mdr).apply(np.sum, axis = 1) / len(M.columns))\n",
    "r_Opt = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "r_Opt['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    r_Opt['Profit'][i] = r_Opt['Profit'][i - 1] + temp[i]\n",
    "    \n",
    "temp = ((Mdrt).apply(np.sum, axis = 1) / len(M.columns))\n",
    "rt_Opt = pd.DataFrame(0, index = M.index, columns = ['Profit'])\n",
    "rt_Opt['Profit'][0] = temp[0]\n",
    "for i in range(1, len(temp)):\n",
    "    rt_Opt['Profit'][i] = rt_Opt['Profit'][i - 1] + temp[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f348024",
   "metadata": {},
   "source": [
    "### Plots\n",
    "#### Study periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d49825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "fig = go.Figure([\n",
    "    go.Bar(name = 'Individual', x = x, y = mq_Individual, marker_color = 'cornflowerblue'),\n",
    "    go.Bar(name = 'Global', x = x, y = mq_Portfolio, marker_color = 'palevioletred'),\n",
    "    go.Bar(name = 'Global sector', x = x, y = mq_Portfolio2, marker_color = 'tan'),\n",
    "    go.Bar(name = 'ARIMA', x = x, y = mq_ARIMA, marker_color = 'orange'),\n",
    "    go.Bar(name = 'FNN', x = x, y = mq_MLP, marker_color = 'darkgray')])\n",
    "fig.update_layout(yaxis_title = 'MAE', xaxis_title = 'Study period', plot_bgcolor = 'white', bargroupgap = 0.0, legend = dict(x = 0, y = 1.025, bgcolor = 'rgba(0,0,0,0)', orientation = 'h'))\n",
    "fig.update_xaxes(ticks = 'outside', showgrid = False, ticklen = 5, dtick = 'M1')\n",
    "fig.update_yaxes(gridwidth = 0.5, gridcolor = 'lightgrey')\n",
    "config = {'toImageButtonOptions': {'scale': 10}}\n",
    "fig.show(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "fig = go.Figure([\n",
    "    go.Bar(name = 'Individual', x = x, y = rp_Individual, marker_color = 'cornflowerblue'),\n",
    "    go.Bar(name = 'Portfolio', x = x, y = rp_Portfolio, marker_color = 'tan'),\n",
    "    go.Bar(name = 'Sector portfolio', x = x, y = rp_Portfolio2, marker_color = 'orange')])\n",
    "fig.update_layout(yaxis_title = 'Return', xaxis_title = 'Study period', plot_bgcolor = 'white', bargroupgap = 0.0, legend = dict(x = -0.05, y = 0.975, bgcolor = 'rgba(0,0,0,0)'))\n",
    "fig.update_xaxes(ticks = 'outside', showgrid = False, ticklen = 5, dtick = 'M1')\n",
    "fig.update_yaxes(zeroline = True, zerolinewidth = 1, zerolinecolor = 'black', gridwidth = 1, gridcolor = 'lightgrey')\n",
    "config = {'toImageButtonOptions': {'scale': 2}}\n",
    "for i in range(len(period_b) - 1):\n",
    "    fig.add_vline(x = i + 1.5 , line_width = 1, line_dash = '7', line_color = 'lightgrey')  \n",
    "fig.show(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f1919",
   "metadata": {},
   "source": [
    "#### Daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "fig = go.Figure([\n",
    "    go.Scatter(name = 'Individual', x = M.index, y = rt_Individual['Profit'], marker_color = 'cornflowerblue', line_width = 10),\n",
    "    go.Scatter(name = 'Global', x = M.index, y = rt_Portfolio['Profit'], marker_color = 'palevioletred', line_width = 10),\n",
    "    go.Scatter(name = 'Global sector', x = M.index, y = rt_Portfolio2['Profit'], marker_color = 'tan', line_width = 10),\n",
    "    #go.Scatter(name = 'ARIMA', x = M.index, y = rt_ARIMA['Profit'], marker_color = 'orange', line_width = 10),\n",
    "    #go.Scatter(name = 'FNN', x = M.index, y = rt_MLP['Profit'], marker_color = 'darkgray', line_width = 10),\n",
    "    go.Scatter(name = 'Buy and hold', x = M.index, y = rt_Bh['Profit'], marker_color = 'seagreen', line_width = 10)])\n",
    "fig.update_layout(yaxis_title = 'Cumulative return', xaxis_title = 'Study period', plot_bgcolor = 'white', legend = dict(x = 0, y = 1.1, bgcolor = 'rgba(0,0,0,0)', orientation = 'h', itemsizing = 'constant'))\n",
    "fig.update_xaxes(ticktext = x, tickvals = M.index[125::250], ticks = 'outside', showgrid = False, ticklen = 5)\n",
    "fig.update_yaxes(zeroline = True, zerolinewidth = 0.5, zerolinecolor = 'black', gridwidth = 0.5, gridcolor = 'lightgrey')\n",
    "config = {'toImageButtonOptions': {'scale': 10}}\n",
    "for i in range(1, len(period_b)):\n",
    "    fig.add_vline(x = period_b[i] , line_width = 0.5, line_dash = '7', line_color = 'lightgrey')  \n",
    "fig.show(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e874362",
   "metadata": {},
   "source": [
    "### Variable importance\n",
    "#### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ea100",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path='logs/Individual/Nr.2/Period_7/Stock_17/version_0/checkpoints/epoch=41-step=420.ckpt'\n",
    "#best_model_path='logs/Global/Nr.2/Period_7/version_0/checkpoints/epoch=15-step=1408.ckpt'\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b2ea8",
   "metadata": {},
   "source": [
    "#### Select stock and study period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_period = 7\n",
    "stock = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaacbde0",
   "metadata": {},
   "source": [
    "#### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Directory = 'C:/.../TFT_for_Stock_Movement_Prediction/data'\n",
    "\n",
    "# Target and return feature\n",
    "CCR = pd.read_csv(os.path.join(Directory, 'CCR.csv'), index_col = [0])\n",
    "\n",
    "### Features\n",
    "## Time features - Categorical\n",
    "time_features = pd.read_csv(os.path.join(Directory, 'time_features.csv'), index_col = [0])['0'].tolist()\n",
    "for i in range(len(time_features)):\n",
    "    locals()[time_features[i]] = pd.read_csv(os.path.join(Directory, time_features[i] + '.csv'), index_col = [0])\n",
    "\n",
    "## Basic historical features\n",
    "bh_features = pd.read_csv(os.path.join(Directory, 'bh_features.csv'), index_col = [0])['0'].tolist()\n",
    "for i in range(len(bh_features)):\n",
    "    locals()[bh_features[i]] = pd.read_csv(os.path.join(Directory, bh_features[i] + '.csv'), index_col = [0])\n",
    "\n",
    "# Categorical\n",
    "bh_categorical_features = pd.read_csv(os.path.join(Directory, 'bh_categorical_features.csv'), index_col = [0])['0'].tolist()\n",
    "\n",
    "# Continuous\n",
    "bh_continuous_features = pd.read_csv(os.path.join(Directory, 'bh_continuous_features.csv'), index_col = [0])['0'].tolist()\n",
    "\n",
    "## Technical indicators - Continuous\n",
    "indicator_features = pd.read_csv(os.path.join(Directory, 'indicator_features.csv'), index_col = [0])['0'].tolist()\n",
    "for i in range(len(indicator_features)):\n",
    "    locals()[indicator_features[i]] = pd.read_csv(os.path.join(Directory, indicator_features[i] + '.csv'), index_col = [0])\n",
    "\n",
    "## Industry sectors\n",
    "Sector = pd.read_csv(os.path.join(Directory, 'portfolio_table.csv'), index_col = [0])\n",
    "\n",
    "# Study periods length\n",
    "period_b = 0, 250, 500, 750, 1000, 1250, 1500, 1750, 2000, 2250\n",
    "period_e = 1000, 1250, 1500, 1750, 2000, 2250, 2500, 2750, 3000, 3250\n",
    "\n",
    "# Split period into training, validation and test set\n",
    "training_size = 750\n",
    "test_size = 250\n",
    "validation_split = 0.2\n",
    "training_cutoff = int(training_size - training_size * validation_split)\n",
    "\n",
    "# Target\n",
    "Target_feature = ['CCR']\n",
    "\n",
    "# Features\n",
    "Feature_type = ['object']\n",
    "time_varying_known_categoricals = time_features\n",
    "time_varying_unknown_categoricals = bh_categorical_features\n",
    "time_varying_unknown_reals = bh_continuous_features + indicator_features\n",
    "static_categoricals = ['Sector']\n",
    "\n",
    "## Model parameters\n",
    "# Dataset\n",
    "max_prediction_length = 1\n",
    "max_encoder_length = 258\n",
    "\n",
    "# Datasets for each study period and stock\n",
    "def dataset(period, stock):\n",
    "    data = pd.DataFrame(index = globals()[Target_feature[0]].index[period_b[period] : period_e[period]])\n",
    "    \n",
    "    ## Add features\n",
    "    data['Time_idx'] = range(period_b[0] + 1, period_e[0] + 1)\n",
    "    data['Target'] = globals()[Target_feature[0]][[globals()[Target_feature[0]].columns[stock]]][period_b[period] : period_e[period]]\n",
    "    data['Stock'] = globals()[Target_feature[0]].columns[stock]\n",
    "    data['Sector'] = globals()[static_categoricals[0]]['Supersector'][stock]\n",
    "\n",
    "    # Time varying known categoricals\n",
    "    for f in range(len(time_varying_known_categoricals)):\n",
    "        data[time_varying_known_categoricals[f]] = globals()[time_varying_known_categoricals[f]].astype(Feature_type[0])\n",
    "    \n",
    "    # Time varying unknown categoricals\n",
    "    for f in range(len(time_varying_unknown_categoricals)):\n",
    "        data[time_varying_unknown_categoricals[f]] = globals()[time_varying_unknown_categoricals[f]][globals()[time_varying_unknown_categoricals[f]].columns[stock]].astype(Feature_type[0])\n",
    "    \n",
    "    # Time varying unknown reals\n",
    "    for f in range(len(time_varying_unknown_reals)):\n",
    "        data[time_varying_unknown_reals[f]] = globals()[time_varying_unknown_reals[f]][globals()[time_varying_unknown_reals[f]].columns[stock]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32090f",
   "metadata": {},
   "source": [
    "#### Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2224a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dataset(study_period - 1, stock - 1)\n",
    "training = TimeSeriesDataSet(\n",
    "data[lambda x: x.Time_idx <= training_cutoff],\n",
    "time_idx = data.columns[0],\n",
    "target = data.columns[1],\n",
    "group_ids = [data.columns[2]],\n",
    "max_encoder_length = max_encoder_length,\n",
    "max_prediction_length = max_prediction_length,\n",
    "time_varying_known_reals = [data.columns[0]],\n",
    "time_varying_unknown_reals = [data.columns[1]] + time_varying_unknown_reals,\n",
    "time_varying_known_categoricals = time_varying_known_categoricals,\n",
    "time_varying_unknown_categoricals = time_varying_unknown_categoricals,\n",
    "target_normalizer = TorchNormalizer())\n",
    "test = TimeSeriesDataSet.from_dataset(training, data, min_prediction_idx = training_size + 1)\n",
    "test_dataloader = test.to_dataloader(train = False, batch_size = test_size)\n",
    "raw_predictions = best_tft.predict(test, mode = 'raw', return_x = True)\n",
    "interpretation = best_tft.interpret_output(raw_predictions.output, reduction = 'sum')\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab11a9",
   "metadata": {},
   "source": [
    "#### Global sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b059da",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_list = []\n",
    "for j in range(len(locals()[Target_feature[0]].columns)):\n",
    "    temp = dataset(study_period - 1, j)\n",
    "    stock_data_list.append(temp)\n",
    "data = pd.concat(stock_data_list, axis = 0).reset_index(drop = True)\n",
    "\n",
    "#### Create dataframe\n",
    "training = TimeSeriesDataSet(\n",
    "data[lambda x: x.Time_idx <= training_cutoff],\n",
    "time_idx = data.columns[0],\n",
    "target = data.columns[1],\n",
    "group_ids = [data.columns[2]],\n",
    "max_encoder_length = max_encoder_length,\n",
    "max_prediction_length = max_prediction_length,\n",
    "time_varying_known_reals = [data.columns[0]],\n",
    "time_varying_unknown_reals = [data.columns[1]] + time_varying_unknown_reals,\n",
    "time_varying_known_categoricals = time_varying_known_categoricals,\n",
    "time_varying_unknown_categoricals = time_varying_unknown_categoricals,\n",
    "static_categoricals = static_categoricals,\n",
    "target_normalizer = GroupNormalizer(groups = [data.columns[2]]))\n",
    "test = TimeSeriesDataSet.from_dataset(training, data, min_prediction_idx = 950 + 1)\n",
    "test_dataloader = test.to_dataloader(train = False, batch_size = test_size)\n",
    "raw_predictions = best_tft.predict(test, mode = 'raw', return_x = True)\n",
    "interpretation = best_tft.interpret_output(raw_predictions.output, reduction = 'sum')\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bafa46",
   "metadata": {},
   "source": [
    "### Lighning logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir='logs/Individual/Period_1'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
